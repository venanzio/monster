\section{Instances of Functor, Applicative, Comonad}\label{sec:type_classes}

This section outlines the Functor, Applicative, and Comonad instances, proving that the functions defined on monadic streams to implement these satisfy the relevant laws. We will prove these with a mixture of equational reasoning (using Haskell), and categorical reasoning, in each case making particular assumptions about the underlying functor.

\subsection{Functor Instance}

To show that $\stream{M}$ is a functor whenever $M$ is, we have to define its behaviour on morphisms: if $f:A\rightarrow B$, then we must define how $f$ maps on monadic streams:
$$
\begin{array}{l}
\stream{M}\,f : \stream{M,A} \rightarrow \stream{M,B}\\
\stream{M}\,f\,(\mcons\,m) = \mcons\,(M\,(f\times \stream{M}\,f)\,m)
\end{array}
$$

This definition complies with the {\em guarded-by-constructors} discipline: the recursive call to $(\stream{M}\,f)$ is mapped to the recursive substreams by the functorial application of the functor $M\,(A \times -)$.
That is: $(\stream{M}\,f)$ will be recursively applied only at the recursive positions inside the shape of $m$.
There are also applications of $f$ to the first element (of type $A$) of the pairs in the $M$-position: this is non-recursive, and therefore not problematic.

The Haskell version of the functorial mapping uses a general stream transformer at the top level: \hcode{transformM} maps between \hcode{MonStr m a} and \hcode{MonStr m b} by mapping through \hcode{m} a function on the components:

\begin{haskell}
uncons :: MonStr m a -> m (a, MonStr m a)
uncons (MCons m) = m

transformM :: Functor m => (a -> MonStr m a -> (b, MonStr m b)) ->
                                  MonStr m a -> MonStr m b
transformM f s = MCons $ fmap (\(h,t) -> f h t) (uncons s)

instance Functor m => Functor (MonStr m) where
   -- fmap :: (a -> b) -> MonStr m a -> MonStr m b
   fmap f = transformM (\a s -> (f a, fmap f s))
\end{haskell}

We can now prove that the functor laws are satisfied by $\stream{M}$: it's functorial mapping preserves identities and composition.
The proofs are straightforward applications of definitions and the functoriality of $M$ and $\times$, except for the use of coinduction;
we are allowed to invoke the laws themselves in their proofs, as long as we use them only in the direct recursive subterms of the $\mcons$ constructor, that is, in the {\em positions} for the container $M\,(A\times -)$.

\begin{lemma}\label{lemma:functor_id}
The identity functor law holds for monadic streams:
$$
\stream{M}\,\id_A = \id_{\stream{M,A}}
$$
\end{lemma}
\begin{proof}
We apply the left-hand side function to an $M$-monster in constructor form:
$$
\begin{array}{ll}
\stream{M}\,\id_A\,(\mcons\,m)\\
{}= \mcons\,(M\,(\id_A\times \stream{M}\,\id_A)\,m)
  & \mbox{by definition}\\
{}= \mcons\,(M\,(\id_A\times \id_{\stream{M,A}})\,m)
  & \mbox{by coinduction hypothesis}\\
{}= \mcons\,(M\,(\id_{A\times \stream{M,A}})\,m)
  & \mbox{by functoriality of }\times\\
{}= \mcons\,(\id_{M\,(A\times \stream{M,A})}\,m)
  & \mbox{by functoriality of }M\\
{}= \mcons\,m
\end{array}
$$
\end{proof}

\begin{lemma}\label{lemma:functor_comp}
The composition functor law holds for monadic streams:

If $f:A\rightarrow B$ and $g:B\rightarrow C$, then
$$
\stream{M}\,(g\comp f) = (\stream{M}\,g) \comp (\stream{M}\,f)
$$
\end{lemma}
\begin{proof}
Let's again apply the left-hand side function to an $M$-monster in constructor form:
$$
\begin{array}{ll}
\stream{M}\,(g\comp f)\,(\mcons\,m)\\
{}= \mcons\,(M\,((g\comp f)\times \stream{M}\,(g\comp f))\,m)
  & \mbox{by definition of }\stream{M}\mbox{ mapping}\\
{}= \mcons\,(M\,((g\comp f)\times ((\stream{M}\,g) \comp (\stream{M}\,f)))\,m)
  & \mbox{by coinduction hypothesis}\\ 
{}= \mcons\,(M\,((g\times \stream{M}\,g) \comp (f\times \stream{M}\,f))\,m)
  & \mbox{by functoriality of }\times\\ 
{}= \mcons\,((M\,(g\times \stream{M}\,g) \comp M\,(f\times \stream{M}\,f))\,m)
  & \mbox{by functoriality of }M\\ 
{}= \mcons\,(M\,(g\times \stream{M}\,g)\, (M\,(f\times \stream{M}\,f)\,m))
  & \mbox{by definition of composition}\\ 
{}= \stream{M}\,g\, (\mcons\,(M\,(f\times \stream{M}\,f)\,m))
  & \mbox{by definition of }\stream{M}\mbox{ mapping}\\ 
{}= \stream{M}\,g\, (\stream{M}\,f\,(\mcons\,m))
  & \mbox{by definition of }\stream{M}\mbox{ mapping}\\ 
{}= ((\stream{M}\,g) \comp (\stream{M}\,f))\,(\mcons\,m)
  & \mbox{by definition of composition}
\end{array}
$$
\end{proof}

We can sum up these results by stating that the monster operator is a functor if the underlying `monad' is (remember that we are not actually assuming that $M$ is a monad yet, but just a type operator).

\begin{theorem}
If $M$ is a functor, $\stream{M}$ is also a functor.
\end{theorem}

\subsection{Applicative instance}

Applicative functors \cite{mcbride/paterson:2008}
extend the mapping operation by allowing function sequencing under the functor.
The Applicative class has two methods: $\apure$, that injects single values into the functor, and $\appl$, that applies functions under the functor.

We assume that the type operator $M$ is an applicative functor, that is, it has methods:
$$
\begin{array}{l}
\apure : A \rightarrow M\,A\\
(\appl): M\,(A\rightarrow B) \rightarrow M\,A \rightarrow M\,B
\end{array}
$$
satisfying the applicative laws.

A typical use of applicative functors is to apply a function of many arguments to several applicative values.
If $g:A_0\rightarrow A_1 \rightarrow \cdots \rightarrow A_n \rightarrow B$ and $m_0:M\,A_0, m_1:M\,A_1, \ldots, m_n:M\,A_n$ , then:
$$
(\apure\,g) \appl m_0 \appl m_1 \appl \cdots \appl m_n : M\,B
$$

In particular, if $g$ is an infix binary operator $(\oplus) : A \rightarrow B \rightarrow C$, then we use the notation:
$$
m_a \alift{\oplus} m_b = (\apure\,(\oplus)) \appl m_a \appl m_b
$$

We will show that $\stream{M}$ is also applicative.
In order to define the methods, we need some auxiliary functions on applicative monsters.
First of all, a simplified version of $\mcons$ that appends a single value in front of a monster.
This in turn uses a similar operator for functors, which appends an $M$-action to the front of a monster
$$
\begin{array}{l}
(\fcons): M\,A \rightarrow \stream{M}\,A \rightarrow \stream{M}\,A\\
m \fcons \sigma = \mcons\, (M\,(\lambda a. \langle a, \sigma\rangle)\,m)\\
\,\\
(\acons): A \rightarrow \stream{M}\,A \rightarrow \stream{M}\,A\\
a \acons \sigma = (\apure\, a) \fcons \sigma
\end{array}
$$

In Haskell:
\begin{haskell}
(<::) :: Functor m => m a -> MonStr m a -> MonStr m a
ma <:: s = MCons (fmap (\a -> (a,s)) ma)

(<:) :: Applicative m => a -> MonStr m a -> MonStr m a
a <: s = pure a <:: s
\end{haskell}

The $\apure$ method for monsters then consists in repeating the same element forever:
$$
\begin{array}{l}
\apure : A \rightarrow \stream{M}\,A\\
\apure\,a = a \acons \apure\,a
\end{array}
$$

We define the function application method by mapping straight function application on the heads and recursive calls on the tails through functorial and applicative lifting:
$$
\begin{array}{l}
(\appl) : \stream{M}\,(A\rightarrow B) \rightarrow \stream{M}\,A \rightarrow \stream{M}\,B\\
(\mcons\,m_f) \appl (\mcons\,m_a)
= \mcons\,(m_f \alift{\pappl} m_a)\\
\qquad \where\;
\langle f,\phi\rangle \pappl \langle a,\sigma\rangle 
= \langle f\,a, \phi \appl \sigma \rangle
\end{array}
$$

This definition recursively applies $\appl$ indirectly in the second components of the arguments of the $\pappl$ operator.
This is lifted to $\alift{\pappl}$, which distributes down through the components of the applicative values $m_f$ and $m_a$, and finally guarded by the constructor $\mcons$.
This guarantees the soundness of the definition according to the {\em guardedness by constructors} criterion.

Here is the definition of the Applicative instance for monsters in Haskell:
\begin{haskell}
transformA :: Applicative m =>
               (a -> MonStr m a -> b -> MonStr m b -> (c, MonStr m c)) ->
               MonStr m a -> MonStr m b -> MonStr m c
transformA f as bs = MCons $ (\(a,as') (b,bs') -> f a as' b bs')
                               <$> uncons as <*> uncons bs

instance Applicative m => Applicative (MonStr m) where
  pure a = a <: pure a
  (<*>) = transformA (\f fs a as -> (f a, fs <*> as))  
\end{haskell}

An applicative instance must satisfy four general laws regulating the interaction of sequencing and pure values and requiring associativity of application.
Preliminary investigation and analysis of specific instances suggest that this is the case for monsters.
A full proof is one of the goals of future work.

\begin{conjecture}\label{lemma:appl_laws}
If $M$ is an applicative functor, $\stream{M}$ is also an applicative functor.
That is, the following laws are satisfied, for every $a:A$, $f:A\rightarrow B$, $\sigma_a:\stream{M}\,A$, $\sigma_f : \stream{M}\,(A\rightarrow B)$, $\sigma_g: \stream{M}\,(B\rightarrow C)$:
$$
\begin{array}{l}
(\apure\,\id) \appl \sigma_a = \sigma_a \\
\apure\,(f\,a) = (\apure\,f) \appl (\apure\,a) \\
\sigma_f \appl (\apure\,a) = (\apure\,(\lambda f. f\,a)) \appl \sigma_f \\
\sigma_g \appl (\sigma_f \appl \sigma_a) = (\sigma_g \alift{\comp} \sigma_f) \appl \sigma_a
\end{array}
$$
\end{conjecture}

\subsection{Comonad instance in Haskell}

Comonads (in cojoin form) are functors with two additional operations: $\eta$ that extracts an element from the functor, and $\mu$, that `duplicates' a functor:
$$
\begin{array}{l}
\eta : W\,A \to A\\
\mu : W\,A \to W\,(W\,A)
\end{array}
$$

For this to constitute a comonad, these operations need to satisfy the comonad laws.

These operations are expressed in Haskell with the \hcode{extract} and \hcode{duplicate} functions of the \hcode{Comonad} type class:

\begin{haskell}
class Functor w => Comonad w where
  extract :: w a -> a
  duplicate :: w a -> w (w a)
\end{haskell}

We believe that monadic streams are comonads, when the underlying functor is a comonad.

In the following Haskell equations, the function \verb+head+ returns the first element of the first pair in the monster, wrapped in the underlying functor. We require the underlying functor to be a comonad, so that we can use \hcode{extract} to remove the functor wrapping.

The proposed \hcode{Comonad} instance for monadic streams is as follows.
\begin{haskell}
head :: Functor m => MonStr m a -> m a
head = fmap fst . uncons

instance Comonad w => Comonad (MonStr w) where
  -- extract :: w a -> a
  extract = extract . head
  -- duplicate :: MonStr w a -> MonStr w (MonStr w a)
  duplicate ms = MCons $ fmap (\(h,t) -> (ms, duplicate t)) (uncons ms)
\end{haskell}

The \verb+duplicate+ function for monadic streams forms a "monster matrix". This is a monadic stream where each element is a monadic stream. In the following proof sketches, we represent this as \hcode{mm(ms)} where \verb+mm(ms) = duplicate ms+.

Intuitively, \verb+mm(ms)+ is a monster where the first element is \verb+ms+, the second is the tail of \verb+ms+, the third is the tail of the tail of \verb+ms+, and so on.


\subsubsection{Comonad law proof sketches}

Sketch of proof that \verb+extract . duplicate == id+

\begin{haskell}
extract . duplicate 
= \ms -> extract (MCons $ fmap (\(h,t) -> (ms, duplicate t)) 
	(uncons ms))
= \ms -> extract (head (MCons $ fmap (\(h,t) -> (ms, duplicate t)) 
	(uncons ms)))
= \ms -> ms 
= id
\end{haskell}

Sketch of proof that \verb+fmap extract . duplicate == id+

\begin{haskell}
fmap extract . duplicate = \ms -> fmap extract (MCons $ fmap (\(h,t) -> 
	(ms, duplicate t)) (uncons ms))
= \ms -> transformM (\a s -> (extract a, fmap extract s)) (MCons $ 
	fmap (\(h,t) -> (ms, duplicate t)) (uncons ms))
  [transformM definition]
= \ms -> MCons $ fmap (\(h,t) -> (extract h, fmap extract t)) 
	(fmap (\(h,t) -> (ms, duplicate t)) (uncons ms)) 
= \ms -> MCons $ fmap (\(h,t) -> (extract ms, fmap extract (duplicate t))) 
	(uncons ms)
  [coinductive hypothesis]
= \ms -> MCons $ fmap (\(h,t) -> ((extract . head) ms, id t)) (uncons ms)
  [(extract . head) ms = a, first element of ms]
= \ms -> MCons $ fmap (\(h,t) -> (a, id t)) (uncons ms)
  [a is defined as the first element of ms, so h = a under the fmap]
= \ms -> ms
= id
\end{haskell}
 
Sketch of proof that \verb+duplicate . duplicate == fmap duplicate . duplicate+

\begin{haskell}
duplicate . duplicate = \ms -> duplicate (duplicate ms)
= \ms -> MCons $ fmap (\(h,t) -> (duplicate ms, duplicate t)) $
	(fmap (\(h,t) -> (ms, duplicate t)) (uncons ms))
= \ms -> MCons $ fmap ((\(h,t) -> (duplicate ms, duplicate (duplicate t))) 
	(uncons ms)
                      
fmap duplicate . duplicate = \ms -> fmap duplicate (MCons $ fmap (\(h,t) -> 
	(ms, duplicate t)) (uncons ms))
= \ms -> transformM (\a s -> (duplicate a, fmap duplicate s)) $
	(MCons $ fmap (\(h,t) -> (ms, duplicate t)) (uncons ms))
= \ms -> MCons $ fmap (\(h,t) -> (\a s -> 
	(duplicate a, fmap duplicate s)) h t) (uncons (MCons $ fmap (\(h,t) -> 
	(ms, duplicate t)) (uncons ms)))
= \ms -> MCons $ fmap (\(h,t) -> (duplicate h, fmap duplicate t)) $ 
	(fmap (\(h,t) -> (ms, duplicate t)) (uncons ms))
= \ms -> MCons $ fmap (\(h,t) -> 
	(duplicate ms, fmap duplicate (duplicate t))) (uncons ms)
  [coinductive hypothesis]
= \ms -> MCons $ fmap ((\(h,t) -> 
	(duplicate ms, duplicate (duplicate t))) (uncons ms)
= duplicate . duplicate
\end{haskell}

As with the applicative functor laws, we are looking to improve these proofs, and also to formulate them in more categorical terms.


%\section{Monad proof}
%\input{monster_article_monad_proof}

\subsection{Monad Counter-examples}

It's natural to ask, given the chosen name for this data structure, whether monsters themselves are monads, at least when the underlying functor is a monad. This is also a natural question because pure streams (with no extra functor guarding the elements) are monads. However, this turns out not to be the case in general (we strongly believe), and we suspect that more constraints need to be placed on the underlying monad for the monster itself to be a monad. Namely, we believe the underlying monad should be idempotent. \\

A monad (in join form) is a functor with two additional operations: $\mathsf{return}$ that trivially injects an element into the functor, and $\mathsf{join}$ that flattens a doubly nested monadic functor into a single layer: 
$$
\begin{array}{l}
\mathsf{return} : A \to M\,A\\
\mathsf{join} : M\,(M\,A) \to M\,A
\end{array}
$$

For this to constitute a monad, these operations need to satisfy the monad laws (we introduce these as needed). 
In Haskell, a monad can be defined with the \hcode{Monad} type class:

\begin{haskell}
class Functor m => Monad m where
  return :: a -> m a
  (>>=) :: m a -> (a -> m a) -> m a
\end{haskell}

For monadic streams to be a monad, we have to be able to inject a pure value into a monster. This is done using \hcode{return}. It is clear that the only possible implementation of \hcode{return} for monadic streams is the same as that of $\apure$ in the applicative functor definition from earlier.
\begin{haskell}
return :: Monad m => a -> MonStr m a
return a = MCons $ fmap (\a -> (a, return a) (return a))
\end{haskell}

We also need to be able to 'flatten' a monster of monsters into a single monster, with respect to certain laws - this is done in Haskell using a function \verb+>>=+, pronounced `bind', its type defined above. 
This flattening is done explicitly in the function \hcode{join :: MonStr m (MonStr m a) -> MonStr m a}: it is always the case that \hcode{(ma >>= f) = join (fmap f ma)} in Haskell. 
This identity lets us prove properties of bind by proving properties of \verb+join+, and visa-versa, as \hcode{join ma = ma >>= id}. \\



In these following counter-examples, we are looking to show that three na√Øve ways of defining the \verb+join+ operation do not work. These cases may or may not cover all possibilities - this is something we have yet to prove.

We will omit the type signature for \verb+join+ in the examples: it is given in the previous paragraph. We also refer to the monsters which are elements of a monster of monsters, as \emph{inner} monsters.

\subsubsection{Case 1}

In this case, we look at the definition of \verb+join+ as taking the 'horizontal' - the first element of each inner stream:
\begin{haskell}
join (MCons mma) = MCons $ do (mas, mma') <- mma
                              fmap (\a -> (a, join mma')) (head mas)
\end{haskell}

However, this definition of \verb+join+ violates the left identity monad law, which states that the following equality must hold:
\begin{haskell}
a :: a
f :: a -> MonStr m a
return a >>= f == f a
\end{haskell}

A witness to this is the monadic stream:
\begin{haskell}
fromStep :: Int -> MonStr (State Int) Int
fromStep n = MCons (state (\x -> ((x, fromStep (n+1)), x+n)))
\end{haskell}
This State-monster, when run (see section 4.4 and 4.5) with an initial number $n$, generates the stream of integers where the first two differ by $n$, the next two differ by $n+1$, and so on.

Running \verb+fromStep 1+ with \verb+1+ produces the stream:
\begin{haskell}
runFBStr (fromStep 1) 1 = 1 <: 2 <: 4 <: 7 <: 11 <: (*...*)
\end{haskell}

Running \hcode{return 1 >>= fromStep} with \verb+1+ produces the stream:
\begin{haskell}
runFBStr (return 1 >>= fromStep) 1 = 1 <: 2 <: 3 <: 4 <: 5 <: (*...*)
\end{haskell}

These are different, so this \verb+join+ instance doesn't satisfy the left identity monad law. \\

Intuitively, we cannot take just the head of each stream, because the first action in each inner monster is `adding $1$' - we end up with a stream where $1$ is added to the the previous element to get the next, which wasn't the definition of \verb+fromStep 1+.


\subsubsection{Case 2}

The next possible definition takes the `vertical' - just the first inner monster:
\begin{haskell}
absorbM :: Monad m => m (MonStr m a) -> MonStr m a
absorbM = MCons . join . fmap uncons

join = absorbM . head 
\end{haskell}
The function \verb+absorbM+ is defined in the library, and simply absorbs a monadic action from outside of a monadic stream. The \verb+join+ function used to define \verb+absorbM+ is that of the underlying monad.

This definition violates the right identity monad law, which states:
\begin{haskell}
ma :: MonStr m a
ma >>= return == ma
\end{haskell}

A witness to this is the pure stream \verb+from n+, defined as
\begin{haskell}
from :: Monad m => Int -> MonStr m a 
from n = n <: from (n+1)
\end{haskell}

\verb+from 0+ gives the stream of natural numbers.
\begin{haskell}
from 0 = 0 <: 1 <: 2 <: 3 <: 4 <: (*...*)
\end{haskell}

\verb+from 0 >>= return+ using this definition of \verb+join+ (taking the first inner monster) gives us a stream of constant zeros:
\begin{haskell}
from 0 >>= return = 0 <: 0 <: 0 <: (*...*)
\end{haskell}

Clearly the \verb+join+ operation cannot be defined as taking the first element of the monster, or the `vertical', since \verb+return 0+ $\neq$ \verb+from 0+.


\subsubsection{Case 3}

The final case we consider is taking the `diagonal'. We define this taking the first element of the first inner monster, the second element of the second inner monster, and so on.

This is defined in Haskell as follows:
\begin{haskell}
tailM :: MonStr m a -> MonStr m a
tailM = absorbM . tail

join (MCons mma) = MCons $ do (mas, mma') <- mma
                              let (ma, ts) = (head mas, fmap tailM mma')
                                 in fmap (\a -> (a, join ts)) ma
\end{haskell}

Similarly to case 1, this definition does not satisfy the left identity monad law, to reiterate:
\begin{haskell}
a :: a
f :: a -> MonStr m a
return a >>= f == f a
\end{haskell} 

The monster \hcode{fromStep n} is a witness to this.

Running \verb+fromStep 1+ with \verb+1+ produces the stream:
\begin{haskell}
runFBStr (fromStep 1) 1 = 1 <: 2 <: 4 <: 7 <: 11 <: (*...*)
\end{haskell}

Running \hcode{return 1 >>= fromStep} with \verb+1+ produces the stream:
\begin{haskell}
runFBStr (return 1 >>= fromStep) 1 = 1 <: 3 <: 8 <: 17 <: 31 <: (*...*)
\end{haskell}

The problem seems to be when taking the diagonal, that when we take the $n$th element from the $n$th inner stream, we need to join together {\em all of the $n$ monadic actions in the inner stream up to that element}. This generates different behaviour because the sequencing of the first $n$ actions in a monster is not in general the same as the $n$th action by itself.

One solution to this could be to only allow the underlying monad to be idempotent \cite{idempotent_monads}. This is a monad that `squares to itself' - the \verb+join+ operation is a natural isomorphism. This isn't the case for this particular instance of the state monad, for example: sequencing two `add 3' actions results extensionally in an `add 6' action.

Taking the diagonal should work as a \verb+join+ operation for monadic streams with idempotent monads, since any order in which you join the actions results in the same action. However, this is quite a strong constraint, and it would be better if there exists a weaker one. \\

All of these cases and code testing the left and right identity monad laws are included in the \hcode{Test.MonadCounterExamples} module, which can be used to validate the reasoning presented.

These three cases may not be exhaustive, so this section exists as an initial sketch (to be completed at a later date) of why monadic streams are not monads (when the underlying functor is a monad). However, we can say for sure that the \verb+join+ operation is not one of the cases considered, which will certainly inform the direction of a concrete proof. 

We also seek to prove that if the monad is idempotent, then the corresponding monadic stream is itself a monad.

