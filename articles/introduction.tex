\section{Introduction}

A monadic stream is a sequence of values in which every element is obtained by triggering a monadic action.
If $\sigma$ is such a stream, it will consist of an action for a certain monad $M$ that, when executed, will return a head (first element) and a tail (continuation of the stream).
This process can be continued in a non-well-founded way: streams constitute a coinductive type.

Using type theoretic notation, the type of streams over a monad $M$ (let's call them {\em $M$-monsters}) with elements of type $A$ is defined as:

$$
\begin{array}[t]{l}
\codata\;
\stream{M}\,A:\set\\
\quad \mcons_M: M\,(A\times \stream{M}\,A)\rightarrow\stream{M}\,A
\end{array}
$$

The keyword $\codata$ indicates that we are defining a coinductive type: in Haskell we just use $\data$ which indicates a recursive type, with no distinction between induction and coinduction. 
The type has a single constructor, $\mcons$, that takes as argument an $M$-action which, when executed, produces a pair of a head in $A$ and a tail $M$-monster.
Depending on the nature of the $M$ monad, head and tail may not be uniquely determined or may invoke some side effects.

Categorically, we can see this type as the {\em final coalgebra} of the functor $F_M\,X = M\,(A\times X)$.
The final coalgebra does not necessarily exist for every $M$, 
but it does for most of the commonly used monads, specifically for those that are container functors \cite{AAG:2005}.

Common implementations of type theory, specifically Coq \cite{coq} and Agda \cite{agda}, allow the definition of coinductive types when the types of constructors (or destructors) satisfy some strict positivity conditions.

The definition of $M$-monsters is very close to that of {\em cofree (or iterative) comonad}, which can be seen as the type of $M$-monsters with a pure 
leading value \cite{AAMV:2003,CUV:2006}.
We introduced them in a previous article \cite{capretta/fowler:2017}, where we proved that polymorphic discrete functions on monadic streams are always continuous.
A slightly different definition of monadic stream functions have been studied previously by Perez, B{\"{a}}renz and Nilsson \cite{PBN:2016} to model signal processors.

The monadic streams definition is a type operator $\stream{M}$ that maps a type $A$ to the type of $M$-monsters with elements of type $A$.
Instantiating $M$ with some of the most well-known monads leads to versions of known data types or to interesting new constructs.
Here are some examples:

\begin{example}[Identity Monad $\rightarrow$ Pure Streams]
The simplest example is to instantiate $M$ with the identity monad:
$\Id$-monsters are equivalent to pure streams.
The usual definition of the type of streams is the following:
$$
\begin{array}[t]{l}
\codata\;
\strsym\,A:\set\\
\quad (\scons): A\rightarrow \strsym\,A \rightarrow\strsym\,A
\end{array}
$$

An element of $(\strsym\,A)$ is an infinite sequence of elements of $A$: $a_0 \scons a_1\scons a_2\scons \cdots$.
As an $\Id$-monster, that is, an element of $\stream{\Id}\,A$, it is written as:
$$
\mcons\,\langle a_0,\mcons \langle a_1, \mcons \langle a_2, \ldots \rangle \rangle \rangle
$$
\end{example}

\begin{example}[Maybe Monad $\rightarrow$ Lazy Lists]
If we instantiate $M$ with the $\maybe$ monad we obtain the type $\stream{\maybe}\,A$, equivalent to the type of lazy lists $\lst{A}$.
The $\maybe$ monad is a functor that adds an extra element to the argument type:
$\maybe\,X$ contains copies of each element $x:X$, denoted by $\just\,x$, plus a {\em empty} element $\nothing$.
So $\maybe\,X \cong X+1$.
The single constructor $\mcons_\maybe: \maybe\,(A\times \stream{\maybe}\,A)\rightarrow\stream{\maybe}\,A$ is equivalent to two constructors (for $\just$ and $\nothing$ respectively):
$$
\begin{array}[t]{l}
\codata\;
\lst{A}:\set\\
\quad (\scons): A\times \lst{A}\rightarrow\lst{A}\\
\quad \nil: \lst{A}.
\end{array}
$$

This means that an element of $\lst{A}$ is either an empty sequence $\nil$ or a non-empty sequence $a\scons \sigma$ where $a:A$ and $\sigma$ is recursively an element of $\lst{A}$.
Since this is a coinductive type, the constructor $(\scons)$ can be applied an infinite number of times.
Therefore $\lst{A}$ is the type of finite and infinite sequences.
For instance, a finite list with two elements would be written, using $\maybe$-monster notation as:
$$
a_0 \scons a_1\scons \nil \cong
\mcons\, (\just\,\langle a_0, 
  \mcons\, (\just\,\langle a_1,
    \mcons\,\nothing\rangle) \rangle)
$$
\end{example}

\begin{example}[List Monad $\rightarrow$ Finitely Branching Trees]
Next, let us take as underlying monad $M = \lstsym $ itself.
In this case each entry in the stream is a list of pairs of heads and tails.
This is equivalent to {\em branch-labelled trees} of arbitrary branching degrees (finite branches if we use only finite lists, but also countably infinite branches if we use lazy lists).
Since the type is coinductive, the trees can be non-well-founded, that is, they may be infinitely deep.
\end{example}

\begin{example}[State Monad $\rightarrow$ State Machines]
If we choose $M$ to be the {\em state transformer} monad, $M$-monsters are state machines that, at every step, produce an output value that depends on an underlying state and change the state itself.
The state transformer monad is defined as $\state_S\,A = S\rightarrow A\times S$, where $S$ is the type of underlying states.
We use the notation $\stmon{S}\,A = \stream{\state_S}\,A$ to denote state monsters.
They will be useful to construct the counterexample to the monad laws in Section \ref{sec:monad}.
\end{example}

\begin{example}[IO Monad $\rightarrow$ Interactive Processes]
Finally, in Haskell user interaction and other system effects are encapsulated in the $\io$ monad. An $\io$ action produces a value that possibly depends and triggers effects. $\io$-monsters are interactive processes that continuously interface with the external world.
\end{example}

A companion paper that we will publish later will present the Haskell monster library that we developed and describe several of its applications. This library can be found on GitHub at \repourl. \\

It is important to make two observations about the underlying ``monad'' $M$.

First, $M$ does not need to be a monad for the definition to make sense. 
In fact we will obtain several interesting results when $M$ satisfies weaker conditions, for example being an applicative functor.
So we will take $M$ to be any type operator (but see second observation) and we will explicitly state what properties we assume about it.
The most important instances are monads and it is convenient to use the facilities of monadic notation in programming and monad theory in reasoning.

The second observation is that it is not guaranteed in general that the $\codata$ type is well-defined.
Haskell will accept the definition when $M$ is any operator, but mathematically the type is well defined only when $F_M\,X = M\,(A\times X)$ is a functor with a final coalgebra.
As stated above, this is the case if $M$ is a container functor and we assume that it is for the rest of the article.

Functions with $M$-monsters as codomain can be defined by explicitly giving a coalgebra.
In practical programming it is more convenient to define functions by {\em corecursive equations} that satisfy the property of {\em guardedness by constructors}:
a corecursive equations is accepted if the right-hand side is a term with a constructor on top and recursive calls occurring only as direct arguments of that constructor.

As an example, here is a function that generates a state machine from a natural number:

$$
\begin{array}{l}
\frominc : \nat \rightarrow \stmon{\nat}\,\nat \\
\frominc\, n = \mcons\, (
   \lambda s. \pair{\pair{s*n}{\frominc\, (n + 1)}}{s+n}
                        )
\end{array}
$$

The machine is a  a State-monster with a parameter $n$,
working with an underlying state $s$.
When executed, it generates the next element, the head of the monster, which is the product value $s*n$; it updates the state to the sum of the old state and the parameter, $s+n$; finally calls itself to generate the tail of the monster with parameter $n+1$.

If we ``run'' (definition given in \ref{sec:monad}) the machine with initial parameter $2$ on an initial state $3$,
it generates the infinite sequence (assuming no other process modifies the state): $6 \scons 15 \scons 32 \scons 60 \scons \cdots$, with the state going through the values $3, 5, 8, 12, 17, \cdots$ and the parameter increasing $2, 3, 4, 5, 6, \cdots$.

The justification of the soundness of the definition is in the fact that the recursive call $\frominc\, (n + 1)$ occurs under the guard of the constructor $\mcons $ and is used to generate the recursive sub-stream of the main output value.
The fact that the input $n+1$ is larger than the original input $n$ is irrelevant to corecursive definitions (contrary to what happens in inductive definitions): what matter is that the first element of the stream and the new state are produced before the call is executed.

Another example is the function from monsters to monsters that increases every element by one.
This is a function polymorphic on $M$ that only assumes that $M$ is a functor.

$$
\begin{array}{l}
\incr : \stream{M}\,\nat \rightarrow \stream{M}\,\nat\\
\incr\,(\mcons\,m) = \mcons\,(M\,(\lambda \pair{k}{\sigma}. \pair{k+1}{\incr\,\sigma})\,m)
\end{array}
$$

The input monster, in constructor form, is $(\mcons\,m)$ where $m$ is an action of type $M\,(\nat\times \stream{M}\,\nat)$.
The right hand-side maps into $m$ (using functoriality of $M$) a function that increases the output value by one and recursively applies $\incr$ to the tail.
We may break down the expression as: $\mcons\,(M\,f\,m)$ where $f\,\pair{k}{\sigma} = \pair{k+1}{\incr\,\sigma}$.
The recursive call $(\incr\,\sigma)$ occurs as the second element of the output of $f$.

This recursive occurrence is justified because it is guarded by $\mcons$ and mapped to the direct subterms inside the monad action.
By the way,
after we prove that $\stream{M}$ is a functor whenever $M$ is in Section \ref{sec:functor}, and that it is applicative whenever $M$ is in Section \ref{sec:applicative},
the definition can be simplified and made more intuitive in the following ways, respectively:
$$
\incr\,\sigma = \stream{M}\,(+1)\,\sigma
\qquad
\incr\,\sigma = \apure\,(+1) \appl \sigma
$$

The general form of a guarded monster function is the following:
$$
\begin{array}{l@{\qquad}l}
\guardf : X \rightarrow \stream{M}\,A
& f : A\times \stream{M}\,A \rightarrow A\times \stream{M}\,A \\
\guardf\,x = \mcons\,(M\,f\,m)
& f\,\langle a, \sigma \rangle = \langle a', \guardf\,x' \rangle
\end{array}
$$
where the displayed occurrence of $\guardf$ in the body of $f$ is the only recursive call: the action $m$ only depends on the input argument $x$, the expressions $a'$ and $x'$ only depend on $a$ and $\sigma$.

In the proofs of our results we will make frequent use of the technique of proof by {\em coinduction} on monsters.
Inductive types comply with an {\em induction principle}, which states that we can prove statements about them by bottom-up recursion on their structure.
Dually, coinductive types comply with a {\em coinduction principle}, which states that we can prove equalities of their elements by top-down {\em co-recursion} on their structure.

Let us illustrate the idea with the example of pure streams:
Suppose that we want to prove that two streams $\sigma_0$ and $\sigma_1$ are equal.
Since streams are infinite sequences of elements, that will require proving equality of their entries in corresponding positions: if $\sigma_0 = a_0\scons a_1\scons a_2\scons \cdots$ and  $\sigma_1 = b_0\scons b_1\scons b_2\scons \cdots$, we must prove $a_0 = b_0$, $a_1 = b_1$, $a_2=b_2$, and so on (we assume equality on streams is extensional).
This requires an infinite sequence of equalities to prove, and clearly we cannot produce all of these explicitly.
However, the proof of equality can be seen itself as a stream of proofs of equalities of each pair of elements in the same positions.
We can use the same principle of guarded recursion to generate all the proofs: we recursively assume that we can prove the equality of the tail streams and we only need to give explicitly the equality of the heads.

In practice the coinduction principle is applied by a corecursive proof that can invoke the statement to be proved under certain structural restrictions.
When proving the equality of two given terms, we can appeal to the statement that we want to prove, as a {\em coinduction hypothesis}, as long as it is {\em guarded by constructors} in the sense that it is only deployed to prove the equality of direct components of the given terms.

Suppose we were proving a proposition about the function $\guardf$ above, of the form $\guardf\,x = e$ for some expression $e$.
In the proof we would be allowed to use the statement itself, as if it were already true, for the recursive occurrence $\guardf\,x'$ in the right-hand side of $f$.

\hide{

As an example,
let us prove a characterization of the function $\frominc$ defined above.
\begin{lemma}
$$
\forall n:\nat. \frominc\,(n+1) = \incr\,(\frominc\,n)
$$
\end{lemma}
\begin{proof}
The proof consists of a sequence of computational steps.
Most of them consists in folding and unfolding definitions and using basic properties of the operators involved, specifically functoriality of the state operator.
The one unusual step is the {\em coinduction hypothesis} in which we allow ourselves to use an instance of the very statement we are proving.

$$
\begin{array}{ll}
\frominc\,(n+1)\\
{}= \mcons\, (\lambda s. \pair{\pair{s+n+1}{\frominc\, (n + 2)}}{s + 1})
  & \mbox{definition of }\frominc\\
{}= \mcons\, (\lambda s. \pair{\pair{s+n+1}{\incr\,(\frominc\,(n+1))}}{s + 1})
  & \mbox{\bf coinduction hypothesis}\\
{}= \mcons\,(
    \begin{array}[t]{l}
    \state_\nat\,(\lambda \pair{k}{\sigma}. \pair{k+1}{\incr\,\sigma})\\
    \quad (\lambda s. \pair{\pair{s+n}{\frominc\,(n+1)}}{s + 1}))
    \end{array}
  & \mbox{functoriality of }\state_\nat\\
{}= \incr\,(\mcons\,(\lambda s. \pair{\pair{s+n}{\frominc\,(n+1)}}{s + 1}))
  & \mbox{definition of }\incr\\
{}= \incr\,(\frominc\,n)
  & \mbox{definition of }\frominc
\end{array}
$$

The coinduction step invokes the main statement of the lemma to rewrite a subterm.
This is apparently circular: we assume the truth of the statement while we are proving it.
However, the occurrence of the hypothesis is guarded by the constructor $\mcons$ and is applied to the recursive argument inside the monadic action.
The monadic action itself is unchanged a part from this recursive application of the hypothesis.
This guarantees the the top levels of the two terms are equal.
It is therefore sound to invoke the hypothesis to prove the lower levels.
\end{proof}

}

We will use this style of reasoning repeatedly in the article.
Most of the proofs consist of equational rewriting, with most steps consisting of term reduction, application of known laws and of previously proved lemmas.
There will usually be a single step justified by {\em coinduction hypothesis}: it will always occur under the guard of a constructor and be mapped inside the monadic action.

See previous survey work \cite{capretta:2011} for an overview of the theory of final coalgebras, coinductive types, corecursive definitions, and proof by coinduction.

The main goal of this article is to study the algebraic properties of monsters, in the form of membership to operator classes.
Is $\stream{M}$ in general a functor, an applicative functor, a monad?
What assumptions do we need to make on $M$ to obtain membership of these classes?
In summary our results are:
\begin{itemize}
\item If $M$ is a functor, $\stream{M}$ is also a functor;
\item If $M$ is an applicative functor, $\stream{M}$ is also an applicative functor;
\item $\stream{M}$ is not a monad is general, even when $M$ is a monad.
\end{itemize}

The proof of the first result is straightforward and unproblematic.
We give the proofs of the functor laws in Section \ref{sec:functor} anyway, as a warm-up in the use of coinduction arguments that will be illuminating in view of the more complex proofs to come.
The proofs of the applicative laws, on the other hand, are surprisingly challenging and require the definition of auxiliary notation and several ancillary lemmas.
Finally, a counterexample using the state transition monad shows that monsters do not form a monad in general. Our counterexample assumes that the join operation takes the {\em diagonal} of a stream of streams.
This doesn't exclude the possibility that monsters would form a monad with a different implementation of join.
However, a general definition that work with any monad $M$ should instantiate to the canonical instance for known monads, and the join operation on pure streams ($\Id$-monsters) operates by taking the diagonal.

These results are important theoretically, they shed light on the abstract properties of monsters, and practically, they allow programmers to use specific notations and extensive libraries for these classes.
