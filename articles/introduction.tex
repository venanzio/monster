\section{Introduction}

A monadic stream is a sequence of values in which every element is obtained by triggering a monadic action.
If $\sigma$ is such a stream, it will consist of an action for a certain monad $M$ that, when executed, will return a head (first element) and a tail (continuation of the stream).
This process can be continued in a non-well-founded way: streams constitute a coinductive type.

Formally the type of streams over a monad $M$ (let's call them {\em $M$-monsters}) with elements of type $A$ is defined, with an Agda-like notation \cite{agda}, as:

$$
\begin{array}[t]{l}
\codata\;
\stream{M,A}:\set\\
\quad \mcons_M: M\,(A\times \stream{M,A})\rightarrow\stream{M,A}
\end{array}
$$

Categorically, we can see this type as the {\em final coalgebra} of the functor $F_M\,X = M\,(A\times X)$.
The final coalgebra does not necessarily exist for every $M$, 
but it does for most of the commonly used monads, specifically for those that are container functors \cite{AAG:2005}.

The definition of $M$-monsters is very close to that of {\em cofree (or iterative) comonad}, which can be seen as the type of $M$-monsters with a pure 
leading value \cite{AAMV:2003,CUV:2006}.

The monadic streams definition is a type operator that maps a type $A$ to the type of $M$-monsters with elements of type $A$; we may indicate the operator by $\stream{M}$ and the type by the slightly different notation $(\stream{M}\,A)$.
This notation will be useful when we prove properties of the operator, for example that it is an applicative functor.

Instantiating $M$ with some of the most well-known monads leads to versions of known data types or to interesting new constructs.

If we instantiate $M$ with the identity monad, we obtain the type of pure streams.
Its usual definition is the following:

$$
\begin{array}[t]{l}
\codata\;
\stream{A}:\set\\
\quad (\scons): \nat\rightarrow \stream{\nat} \rightarrow\stream{\nat}.
\end{array}
$$

An element of $\stream{A}$ is an infinite sequence of elements of $A$: $a_0 \scons a_1\scons a_2\scons \cdots$.




If we instantiate $M$ with the $\maybe$ monad we obtain the type $\stream{\maybe,A}$, equivalent to the type of lazy lists $\lst{A}$.
The $\maybe$ monad is a functor that adds an extra element to the argument type:
$\maybe\,X$ contains copies of each element $x:X$, denoted by $\just\,x$, plus a {\em empty} element $\nothing$.
So $\maybe\,X \cong X+1$.
The single constructor $\mcons_\maybe: \maybe\,(A\times \stream{\maybe,A})\rightarrow\stream{\maybe,A}$ is equivalent to two constructors (for $\nothing$ and $\just$):

$$
\begin{array}[t]{l}
\codata\;
\lst{A}:\set\\
\quad (\scons): A\times \lst{A}\rightarrow\lst{A}\\
\quad \nil: \lst{A}.
\end{array}
$$

This means that an element of $\lst{A}$ is either an empty sequence $\nil$ or a non-empty sequence $a\scons \sigma$ where $a:A$ and $\sigma$ is recursively an element of $\lst{A}$.
Since this is a coinductive type, the constructor $(\scons)$ can be applied an infinite number of times.
Therefore $\lst{A}$ is the type of finite and infinite sequences. \\

Another example is when the underlying monad is $M = \lstsym $ itself.
In this case each entry in the stream is a list of pairs of heads and tails.
This is equivalent trees of arbitrary branching degrees (finitely branching if we use only finite lists, but also countably infinite branches if we use lazy lists).
Since the type is coinductive, the trees can be non-well-founded, that is, they may be infinitely deep.


It is important to make two observations about $M$.

First, $M$ does not need to be a monad for the definition to make sense. 
In fact we will obtain several interesting results when $M$ satisfies weaker conditions, for example being just a functor.
So we will take $M$ to be any type operator (but see second observation) and we will explicitly state what properties we assume about it.
The most important instances are monads and it is convenient to use the facilities of monadic notation in programming and monad theory in reasoning.

The second observation is that it is not guaranteed in general that the $\codata$ type is well-defined.
Haskell will accept the definition when $M$ is any operator, but mathematically the type is well defined only when $F_M\,X = M\,(A\times X)$ is a functor with a final coalgebra.


We can define a function into $\stream{A}$ by defining a coalgebra on the domain type $A$, which in this case is $\nat$.
For example, if we want to define a function that maps any natural number $n$ to the stream of numbers starting from $n$, $n\scons (n+1) \scons (n+2) \scons (n+3) \scons \cdots$, we can do it by using a coalgebra on $\nat$:

$$
\begin{array}{l}
\xi : \nat \rightarrow \nat\times \nat\\
\xi\,n = \langle n,n+1\rangle
\end{array}
$$

(Note that the target type of the coalgebra is $F(\nat) = \nat\times\nat$: The first $\nat$ is the parameter of the functor, while the second $\nat$ is the carrier of the coalgebra.)
The anamorphism $\sfr = \ana{\xi}:\nat \rightarrow \stream{\nat}$ maps $n$ to the stream starting at $n$.

In practical programming, we often let the coalgebra $\xi$ be implicit by directly defining the function $\ana{\xi}$ recursively.
For example, the function above can be defined as:

$$
\begin{array}{l}
\sfr: \nat \rightarrow \stream{\nat}\\
\sfr\,n = n \scons \sfr\,(n+1)
\end{array}
$$

Here the presence of the parameter $n$ and the argument of the recursive call $n+1$ implicitly give the coalgebra $n \mapsto \langle n, n+1\rangle$.
This is a general programming pattern: we specify a function by equations that directly give the head of the resulting stream, and indirectly determine the tail
 by applying recursively the function at the top of the second argument of the constructor ${\scons}$.
We say that the recursive call is {\em guarded by the constructor}.
When this happens we can always find a coalgebra that justifies the definition.

In practical programming we can use a more liberal methodology, coding programs by equations that are not strictly guarded by constructors, but can be reduced to that form (or directly to coalgebra form) by some standard transformation.
For example, a different way of defining the function $\sfr$ is:

$$
\begin{array}{l}
\sfp: \nat \rightarrow \stream{\nat}\\
\sfp\,n = n \scons (\sfp\,n \oplus \bar{1})
\end{array}
$$

where $\oplus$ is the pointwise addition of streams and $\bar{1}$ is the constant stream of ones:

$$
\begin{array}{l}
(\oplus): \stream{\nat}\rightarrow \stream{\nat}\rightarrow \stream{\nat}\\
\sigma_1 \oplus \sigma_2 = (\head\,\sigma_1 + \head\,\sigma_2) \scons (\tail\,\sigma_1 \oplus \tail\,\sigma_2)
\end{array}
\quad
\begin{array}{l}
\bar{\cdot}: A \rightarrow \stream{A}\\
\bar{x} = x \scons \bar{x}
\end{array}
$$

Notice that, while the definitions of $\oplus$ and $\bar{\cdot}$ are correctly guarded by constructors, the definition of $\sfp$ is not strictly guarded: the recursive call doesn't occur immediately at the top of the second argument of the constructor $\scons$, but instead as an argument of the $\oplus$ operator.
However, it is relatively easy to modify the definition to make it comply with the strict guardedness condition \cite{capretta:2011}.
We will allow ourselves to use this more lax definition style. \\

A class of functors for which the existence of a final coalgebra is guaranteed is that of {\em containers} \cite{AAG:2005}: they are a generalization of tree constructors in which any type can be used for branching; this leads to generalized types of non-well-founded trees.

{\em Guardedness by constructors} is common good criterion for the acceptability of recursive definitions with a final coalgebra as its codomain: it accepts any recursive equations in which the right-hand side is a term with a constructor on top and recursive calls occurring only as direct arguments of that constructor.

See previous survey work \cite{capretta:2011} for an overview of the theory of final coalgebras, coinductive types, and corecursive definitions.

The definition of $\stream{M,A}$ is not meaningful for all $M$s, because the final coalgebra may not exist or not be unique.
A useful result is that a functor has a final coalgebra if it is a container \cite{AAG:2005}, and $F_M$ is a container if $M$ is \cite{capretta/fowler:2017}.
This is the case for all the instances that we consider (but there are well known counterexamples, like the powerset functor and the continuation functor).

The idea of a container functor $F$ is that, given a type $X$, the elements of $F\,X$ are built by constructors that specify a {\em shape} together with {\em positions} inside the shape where elements of $X$ can be inserted.
For example, the functor $\maybe$ has two shapes: $\nothing$, with not positions at all, and $\just$, with a single position.
Another example is the $\lstsym$ functor: we can see it as having an infinite number of shapes: one shape for every natural number $n$, with $n$ positions:

$$
\begin{array}{llcll}
\mbox{shape $n$: } \quad [ & \bullet,  & \cdots ,  & \bullet & ]\\
\mbox{positions: }     & \uparrow &       & \uparrow
\end{array}
$$

In our case, if $M$ is a container, the functor $F_M$ is a container where the shapes are extended with an element of $A$ paired to every positions.
For example, if $M$ is $\lstsym$, the general form of shapes and positions is this:

$$
\begin{array}{lrcrl}
\mbox{shape $n$: } \quad [ & \langle a_0, \bullet\rangle,  
                           & \cdots ,  
                           & \langle a_{n-1}, \bullet \rangle & ]\\
\mbox{positions: }     & \uparrow\hspace{6pt} &       & \uparrow\hspace{4pt}
\end{array}
$$

The coinductive types we use are always final coalgebras of containers.
From now on we silently assume that $M$ is a container and that the final coalgebra exists.
Cofinality means that we can define functions into the coalgebra by {\em corecursion} and we can prove properties of its elements by {\em coinduction}.
This means that we can define a function by equations that recursively apply the function itself to the elements in the positions of the shapes, and we can prove properties of elements by invoking the statement we want to prove on the elements in the positions.


One final observation is about the distinction between {\em inductive} and {\em coinductive} types.
We have defined pure streams, lazy lists, monadic streams as coinductive types, using the keyword $\codata$.
Every container functor also has an inductive type, defined similarly but with the keyword $\data$.
For example, if we change the keyword in the definition of lazy lists, we obtain the type of finite lists:

$$
\begin{array}[t]{l}
\data\;
\flst{A}:\set\\
\quad (\scons): A\times \flst{A}\rightarrow\flst{A}\\
\quad \nil: \flst{A}.
\end{array}
$$

This change requires every element of $\flst{A}$ to be well-founded, that is, to hit the base case $\nil$ after a finite number of steps.
Inductive types are much more well known that the coinductive ones, and have been a staple of computer science for decades.
The field of coinductive types is instead much younger and still under development.

Inductive types can be characterized dually to coinductive ones as initial algebras of functors.
The pattern of definition of function on them is different: we use the common {\em inductive recursion} style, rather than guardedness.

An inductive type is always a subset of the coinductive type for the same functor (finite lists are contained in lazy lists), but the coinductive type contains extra infinite elements.

